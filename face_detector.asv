function points = face_detector(video)
lipDetector = vision.CascadeObjectDetector('Mouth','MergeThreshold',8);

v=VideoReader(video);

one_frame = readFrame(v);
pointTracker = vision.PointTracker('MaxBidirectionalError', 2);
my_bboxes = step(lipDetector, one_frame);

extracted_frame = applyFeatureExtraction(one_frame,lipDetector);

function extracted_img = applyFeatureExtraction(img,lipDetector)
    new_bboxes = step(lipDetector, img);
    if ~isempty(new_bboxes)
        my_bboxes = new_bboxes;
    end
    mouthRegion = imcrop(img,my_bboxes(1,:));
    grayMouth = rgb2gray(mouthRegion);
    extracted_img = edge(grayMouth,'canny');
end
points = detectMinEigenFeatures(extracted_frame);
scale_factor = [600,800];
%height = scale_factor/size(extracted_frame,1);
%width = scale_factor/size(extracted_frame,2);
%extracted_frame = imresize(extracted_frame,height);
extracted_frame = imresize(extracted_frame,scale_factor);
initialize(pointTracker, points.Location, uint8(extracted_frame));
frameData = struct('Points', {});
k=1;
while hasFrame(v)
    one_frame = readFrame(v);
    extracted_frame = applyFeatureExtraction(one_frame,lipDetector,my_bboxes);
    %height = scale_factor/size(extracted_frame,1);
    %width = scale_factor/size(extracted_frame,2);
    %extracted_frame = imresize(extracted_frame,height);
    extracted_frame = imresize(extracted_frame,scale_factor);
    [points, ~] = step(pointTracker, uint8(extracted_frame));
    frameData(k).Points = points; 
    k=k+1;
    
end
points = frameData.Points;
end

